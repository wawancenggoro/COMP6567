{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IrisDataset(Dataset):\n",
    "  def __init__(self, X, y):\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    X = torch.Tensor(self.X[index])\n",
    "    y = torch.LongTensor(self.y[index, None])\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open dataset from csv\n",
    "dataset = pd.read_csv('iris.csv')\n",
    "\n",
    "# transform labels to numerics\n",
    "dataset.loc[dataset.species=='Iris-setosa', 'species'] = 0\n",
    "dataset.loc[dataset.species=='Iris-versicolor', 'species'] = 1\n",
    "dataset.loc[dataset.species=='Iris-virginica', 'species'] = 2\n",
    "\n",
    "# get the features and labels from the dataset\n",
    "X = dataset[dataset.columns[0:4]].values\n",
    "y = dataset.species.values.astype(np.int64)\n",
    "\n",
    "# preprocessing with z-score normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(train_X, train_y, \n",
    "                                                      test_size=0.2)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = IrisDataset(train_X, train_y)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, \n",
    "                             shuffle=True, num_workers=0)\n",
    "\n",
    "valid_ds = IrisDataset(valid_X, valid_y)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=16, \n",
    "                             shuffle=False, num_workers=0)\n",
    "\n",
    "test_ds = IrisDataset(test_X, test_y)\n",
    "test_loader = DataLoader(test_ds, batch_size=16, \n",
    "                            shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    # define nn\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 100)\n",
    "        self.bn1 = nn.BatchNorm1d(100)\n",
    "        \n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        \n",
    "        self.fc3 = nn.Linear(100, 3)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.fc1(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.bn1(X)\n",
    "        X = self.fc2(X)\n",
    "        X = F.relu(X)\n",
    "        X = self.bn2(X)\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the model\n",
    "net = Net()\n",
    "\n",
    "# Choosing the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Choosing the optimizer\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# alternatif optimizer: Adam\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "Epoch 0\n",
      "training loss: 0.74690193\n",
      "validation loss: 0.45710459\n",
      "=========================================================\n",
      "Epoch 1\n",
      "training loss: 0.44675884\n",
      "validation loss: 0.36411005\n",
      "=========================================================\n",
      "Epoch 2\n",
      "training loss: 0.29925454\n",
      "validation loss: 0.30613029\n",
      "=========================================================\n",
      "Epoch 3\n",
      "training loss: 0.27498662\n",
      "validation loss: 0.27199304\n",
      "=========================================================\n",
      "Epoch 4\n",
      "training loss: 0.23881148\n",
      "validation loss: 0.24995586\n",
      "=========================================================\n",
      "Epoch 5\n",
      "training loss: 0.19682352\n",
      "validation loss: 0.23347846\n",
      "=========================================================\n",
      "Epoch 6\n",
      "training loss: 0.18311322\n",
      "validation loss: 0.22253154\n",
      "=========================================================\n",
      "Epoch 7\n",
      "training loss: 0.16743918\n",
      "validation loss: 0.21556090\n",
      "=========================================================\n",
      "Epoch 8\n",
      "training loss: 0.16049536\n",
      "validation loss: 0.20131108\n",
      "=========================================================\n",
      "Epoch 9\n",
      "training loss: 0.22602369\n",
      "validation loss: 0.19717659\n",
      "=========================================================\n",
      "Epoch 10\n",
      "training loss: 0.13795795\n",
      "validation loss: 0.19873843\n",
      "=========================================================\n",
      "Epoch 11\n",
      "training loss: 0.11190017\n",
      "validation loss: 0.19884346\n",
      "=========================================================\n",
      "Epoch 12\n",
      "training loss: 0.11825664\n",
      "validation loss: 0.19744515\n",
      "=========================================================\n",
      "Epoch 13\n",
      "training loss: 0.12582587\n",
      "validation loss: 0.19382158\n",
      "=========================================================\n",
      "Epoch 14\n",
      "training loss: 0.10491669\n",
      "validation loss: 0.19083813\n",
      "=========================================================\n",
      "Epoch 15\n",
      "training loss: 0.11415736\n",
      "validation loss: 0.18153647\n",
      "=========================================================\n",
      "Epoch 16\n",
      "training loss: 0.09383804\n",
      "validation loss: 0.18007942\n",
      "=========================================================\n",
      "Epoch 17\n",
      "training loss: 0.11778799\n",
      "validation loss: 0.18296164\n",
      "=========================================================\n",
      "Epoch 18\n",
      "training loss: 0.12911934\n",
      "validation loss: 0.17097139\n",
      "=========================================================\n",
      "Epoch 19\n",
      "training loss: 0.09448433\n",
      "validation loss: 0.17018063\n",
      "=========================================================\n",
      "Epoch 20\n",
      "training loss: 0.09442958\n",
      "validation loss: 0.17049986\n",
      "=========================================================\n",
      "Epoch 21\n",
      "training loss: 0.10718650\n",
      "validation loss: 0.17738329\n",
      "=========================================================\n",
      "Epoch 22\n",
      "training loss: 0.09881865\n",
      "validation loss: 0.17815705\n",
      "=========================================================\n",
      "Epoch 23\n",
      "training loss: 0.11429307\n",
      "validation loss: 0.17684089\n",
      "=========================================================\n",
      "Epoch 24\n",
      "training loss: 0.07615716\n",
      "validation loss: 0.17745137\n",
      "=========================================================\n",
      "Epoch 25\n",
      "training loss: 0.09741344\n",
      "validation loss: 0.16372548\n",
      "=========================================================\n",
      "Epoch 26\n",
      "training loss: 0.09085176\n",
      "validation loss: 0.17858836\n",
      "=========================================================\n",
      "Epoch 27\n",
      "training loss: 0.10732043\n",
      "validation loss: 0.15300111\n",
      "=========================================================\n",
      "Epoch 28\n",
      "training loss: 0.06958267\n",
      "validation loss: 0.16284628\n",
      "=========================================================\n",
      "Epoch 29\n",
      "training loss: 0.10154918\n",
      "validation loss: 0.16422330\n",
      "=========================================================\n",
      "Epoch 30\n",
      "training loss: 0.09318166\n",
      "validation loss: 0.15990525\n",
      "=========================================================\n",
      "Epoch 31\n",
      "training loss: 0.06180486\n",
      "validation loss: 0.16109225\n",
      "=========================================================\n",
      "Epoch 32\n",
      "training loss: 0.09306503\n",
      "validation loss: 0.17112204\n",
      "=========================================================\n",
      "Epoch 33\n",
      "training loss: 0.11311972\n",
      "validation loss: 0.14993283\n",
      "=========================================================\n",
      "Epoch 34\n",
      "training loss: 0.10622778\n",
      "validation loss: 0.14413419\n",
      "=========================================================\n",
      "Epoch 35\n",
      "training loss: 0.04674019\n",
      "validation loss: 0.15276207\n",
      "=========================================================\n",
      "Epoch 36\n",
      "training loss: 0.11984452\n",
      "validation loss: 0.15757225\n",
      "=========================================================\n",
      "Epoch 37\n",
      "training loss: 0.07297175\n",
      "validation loss: 0.16109148\n",
      "=========================================================\n",
      "Epoch 38\n",
      "training loss: 0.16301249\n",
      "validation loss: 0.14987227\n",
      "=========================================================\n",
      "Epoch 39\n",
      "training loss: 0.10468025\n",
      "validation loss: 0.16219173\n",
      "=========================================================\n",
      "Epoch 40\n",
      "training loss: 0.09292930\n",
      "validation loss: 0.16376318\n",
      "=========================================================\n",
      "Epoch 41\n",
      "training loss: 0.08609568\n",
      "validation loss: 0.16771019\n",
      "=========================================================\n",
      "Epoch 42\n",
      "training loss: 0.07816389\n",
      "validation loss: 0.17445889\n",
      "=========================================================\n",
      "Epoch 43\n",
      "training loss: 0.05722218\n",
      "validation loss: 0.17588869\n",
      "=========================================================\n",
      "Epoch 44\n",
      "training loss: 0.08145615\n",
      "validation loss: 0.18474495\n",
      "=========================================================\n",
      "Epoch 45\n",
      "training loss: 0.10002980\n",
      "validation loss: 0.18479876\n",
      "=========================================================\n",
      "Epoch 46\n",
      "training loss: 0.05227272\n",
      "validation loss: 0.19108380\n",
      "=========================================================\n",
      "Epoch 47\n",
      "training loss: 0.06918658\n",
      "validation loss: 0.18700467\n",
      "=========================================================\n",
      "Epoch 48\n",
      "training loss: 0.09114256\n",
      "validation loss: 0.18656653\n",
      "=========================================================\n",
      "Epoch 49\n",
      "training loss: 0.05037573\n",
      "validation loss: 0.17124152\n",
      "=========================================================\n",
      "Epoch 50\n",
      "training loss: 0.05962798\n",
      "validation loss: 0.16773364\n",
      "=========================================================\n",
      "Epoch 51\n",
      "training loss: 0.05621682\n",
      "validation loss: 0.17838998\n",
      "=========================================================\n",
      "Epoch 52\n",
      "training loss: 0.08950260\n",
      "validation loss: 0.16131583\n",
      "=========================================================\n",
      "Epoch 53\n",
      "training loss: 0.14385907\n",
      "validation loss: 0.16947693\n",
      "=========================================================\n",
      "Epoch 54\n",
      "training loss: 0.03836528\n",
      "validation loss: 0.17508039\n",
      "=========================================================\n",
      "Epoch 55\n",
      "training loss: 0.11672047\n",
      "validation loss: 0.17560688\n",
      "=========================================================\n",
      "Epoch 56\n",
      "training loss: 0.04002391\n",
      "validation loss: 0.17754787\n",
      "=========================================================\n",
      "Epoch 57\n",
      "training loss: 0.09444800\n",
      "validation loss: 0.17228179\n",
      "=========================================================\n",
      "Epoch 58\n",
      "training loss: 0.05414055\n",
      "validation loss: 0.17774305\n",
      "=========================================================\n",
      "Epoch 59\n",
      "training loss: 0.07366677\n",
      "validation loss: 0.18689561\n",
      "=========================================================\n",
      "Epoch 60\n",
      "training loss: 0.04141770\n",
      "validation loss: 0.18324132\n",
      "=========================================================\n",
      "Epoch 61\n",
      "training loss: 0.07343894\n",
      "validation loss: 0.17229043\n",
      "=========================================================\n",
      "Epoch 62\n",
      "training loss: 0.05731790\n",
      "validation loss: 0.18781230\n",
      "=========================================================\n",
      "Epoch 63\n",
      "training loss: 0.08370212\n",
      "validation loss: 0.19626547\n",
      "=========================================================\n",
      "Epoch 64\n",
      "training loss: 0.07956331\n",
      "validation loss: 0.18902972\n",
      "=========================================================\n",
      "Epoch 65\n",
      "training loss: 0.03977016\n",
      "validation loss: 0.19547307\n",
      "=========================================================\n",
      "Epoch 66\n",
      "training loss: 0.12202734\n",
      "validation loss: 0.19980839\n",
      "=========================================================\n",
      "Epoch 67\n",
      "training loss: 0.03643453\n",
      "validation loss: 0.19453046\n",
      "=========================================================\n",
      "Epoch 68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.04165591\n",
      "validation loss: 0.18115400\n",
      "=========================================================\n",
      "Epoch 69\n",
      "training loss: 0.06130149\n",
      "validation loss: 0.18509412\n",
      "=========================================================\n",
      "Epoch 70\n",
      "training loss: 0.05012716\n",
      "validation loss: 0.19459513\n",
      "=========================================================\n",
      "Epoch 71\n",
      "training loss: 0.05287370\n",
      "validation loss: 0.19472787\n",
      "=========================================================\n",
      "Epoch 72\n",
      "training loss: 0.13133316\n",
      "validation loss: 0.18322842\n",
      "=========================================================\n",
      "Epoch 73\n",
      "training loss: 0.09749556\n",
      "validation loss: 0.16207951\n",
      "=========================================================\n",
      "Epoch 74\n",
      "training loss: 0.07579414\n",
      "validation loss: 0.14050327\n",
      "=========================================================\n",
      "Epoch 75\n",
      "training loss: 0.04901645\n",
      "validation loss: 0.14915586\n",
      "=========================================================\n",
      "Epoch 76\n",
      "training loss: 0.07260532\n",
      "validation loss: 0.15514840\n",
      "=========================================================\n",
      "Epoch 77\n",
      "training loss: 0.03475225\n",
      "validation loss: 0.16461301\n",
      "=========================================================\n",
      "Epoch 78\n",
      "training loss: 0.04056688\n",
      "validation loss: 0.17251182\n",
      "=========================================================\n",
      "Epoch 79\n",
      "training loss: 0.03628836\n",
      "validation loss: 0.17719275\n",
      "=========================================================\n",
      "Epoch 80\n",
      "training loss: 0.06203936\n",
      "validation loss: 0.17115204\n",
      "=========================================================\n",
      "Epoch 81\n",
      "training loss: 0.15991934\n",
      "validation loss: 0.16355705\n",
      "=========================================================\n",
      "Epoch 82\n",
      "training loss: 0.05065583\n",
      "validation loss: 0.16670078\n",
      "=========================================================\n",
      "Epoch 83\n",
      "training loss: 0.04559316\n",
      "validation loss: 0.17395857\n",
      "=========================================================\n",
      "Epoch 84\n",
      "training loss: 0.08239748\n",
      "validation loss: 0.16343686\n",
      "=========================================================\n",
      "Epoch 85\n",
      "training loss: 0.03962718\n",
      "validation loss: 0.15592030\n",
      "=========================================================\n",
      "Epoch 86\n",
      "training loss: 0.02461766\n",
      "validation loss: 0.15850241\n",
      "=========================================================\n",
      "Epoch 87\n",
      "training loss: 0.04632116\n",
      "validation loss: 0.15299113\n",
      "=========================================================\n",
      "Epoch 88\n",
      "training loss: 0.07073308\n",
      "validation loss: 0.15814294\n",
      "=========================================================\n",
      "Epoch 89\n",
      "training loss: 0.01889788\n",
      "validation loss: 0.15944995\n",
      "=========================================================\n",
      "Epoch 90\n",
      "training loss: 0.08667839\n",
      "validation loss: 0.16813023\n",
      "=========================================================\n",
      "Epoch 91\n",
      "training loss: 0.05555108\n",
      "validation loss: 0.17637487\n",
      "=========================================================\n",
      "Epoch 92\n",
      "training loss: 0.03610794\n",
      "validation loss: 0.18105629\n",
      "=========================================================\n",
      "Epoch 93\n",
      "training loss: 0.06830753\n",
      "validation loss: 0.18167944\n",
      "=========================================================\n",
      "Epoch 94\n",
      "training loss: 0.03837258\n",
      "validation loss: 0.17308496\n",
      "=========================================================\n",
      "Epoch 95\n",
      "training loss: 0.03291807\n",
      "validation loss: 0.16364151\n",
      "=========================================================\n",
      "Epoch 96\n",
      "training loss: 0.03661453\n",
      "validation loss: 0.14555281\n",
      "=========================================================\n",
      "Epoch 97\n",
      "training loss: 0.04019981\n",
      "validation loss: 0.15813322\n",
      "=========================================================\n",
      "Epoch 98\n",
      "training loss: 0.02937000\n",
      "validation loss: 0.16590416\n",
      "=========================================================\n",
      "Epoch 99\n",
      "training loss: 0.03326399\n",
      "validation loss: 0.17164846\n",
      "=========================================================\n",
      "Epoch 100\n",
      "training loss: 0.12063844\n",
      "validation loss: 0.19000195\n",
      "=========================================================\n",
      "Epoch 101\n",
      "training loss: 0.07068298\n",
      "validation loss: 0.16628820\n",
      "=========================================================\n",
      "Epoch 102\n",
      "training loss: 0.03147320\n",
      "validation loss: 0.16343996\n",
      "=========================================================\n",
      "Epoch 103\n",
      "training loss: 0.03887377\n",
      "validation loss: 0.17607306\n",
      "=========================================================\n",
      "Epoch 104\n",
      "training loss: 0.04335721\n",
      "validation loss: 0.18007195\n",
      "=========================================================\n",
      "Epoch 105\n",
      "training loss: 0.03355192\n",
      "validation loss: 0.16954492\n",
      "=========================================================\n",
      "Epoch 106\n",
      "training loss: 0.04796675\n",
      "validation loss: 0.19177800\n",
      "=========================================================\n",
      "Epoch 107\n",
      "training loss: 0.05035793\n",
      "validation loss: 0.18694097\n",
      "=========================================================\n",
      "Epoch 108\n",
      "training loss: 0.04221293\n",
      "validation loss: 0.17739250\n",
      "=========================================================\n",
      "Epoch 109\n",
      "training loss: 0.07262299\n",
      "validation loss: 0.17787136\n",
      "=========================================================\n",
      "Epoch 110\n",
      "training loss: 0.07089481\n",
      "validation loss: 0.17586273\n",
      "=========================================================\n",
      "Epoch 111\n",
      "training loss: 0.05878444\n",
      "validation loss: 0.18158764\n",
      "=========================================================\n",
      "Epoch 112\n",
      "training loss: 0.26856509\n",
      "validation loss: 0.18606797\n",
      "=========================================================\n",
      "Epoch 113\n",
      "training loss: 0.03273640\n",
      "validation loss: 0.17638907\n",
      "=========================================================\n",
      "Epoch 114\n",
      "training loss: 0.01649275\n",
      "validation loss: 0.17207417\n",
      "=========================================================\n",
      "Epoch 115\n",
      "training loss: 0.02856772\n",
      "validation loss: 0.16268575\n",
      "=========================================================\n",
      "Epoch 116\n",
      "training loss: 0.04502799\n",
      "validation loss: 0.16355817\n",
      "=========================================================\n",
      "Epoch 117\n",
      "training loss: 0.02152067\n",
      "validation loss: 0.17140238\n",
      "=========================================================\n",
      "Epoch 118\n",
      "training loss: 0.02907109\n",
      "validation loss: 0.17690963\n",
      "=========================================================\n",
      "Epoch 119\n",
      "training loss: 0.03894314\n",
      "validation loss: 0.18438539\n",
      "=========================================================\n",
      "Epoch 120\n",
      "training loss: 0.03993391\n",
      "validation loss: 0.16513975\n",
      "=========================================================\n",
      "Epoch 121\n",
      "training loss: 0.01512432\n",
      "validation loss: 0.17487192\n",
      "=========================================================\n",
      "Epoch 122\n",
      "training loss: 0.04045323\n",
      "validation loss: 0.18323998\n",
      "=========================================================\n",
      "Epoch 123\n",
      "training loss: 0.04248504\n",
      "validation loss: 0.20316604\n",
      "=========================================================\n",
      "Epoch 124\n",
      "training loss: 0.02871823\n",
      "validation loss: 0.19208659\n",
      "=========================================================\n",
      "Epoch 125\n",
      "training loss: 0.05473422\n",
      "validation loss: 0.18436132\n",
      "=========================================================\n",
      "Epoch 126\n",
      "training loss: 0.04701813\n",
      "validation loss: 0.16543601\n",
      "=========================================================\n",
      "Epoch 127\n",
      "training loss: 0.05958482\n",
      "validation loss: 0.17520754\n",
      "=========================================================\n",
      "Epoch 128\n",
      "training loss: 0.02424676\n",
      "validation loss: 0.17268340\n",
      "=========================================================\n",
      "Epoch 129\n",
      "training loss: 0.10472826\n",
      "validation loss: 0.16234013\n",
      "=========================================================\n",
      "Epoch 130\n",
      "training loss: 0.03356226\n",
      "validation loss: 0.14838475\n",
      "=========================================================\n",
      "Epoch 131\n",
      "training loss: 0.01534677\n",
      "validation loss: 0.16114765\n",
      "=========================================================\n",
      "Epoch 132\n",
      "training loss: 0.03056220\n",
      "validation loss: 0.16672921\n",
      "=========================================================\n",
      "Epoch 133\n",
      "training loss: 0.03747050\n",
      "validation loss: 0.18283966\n",
      "=========================================================\n",
      "Epoch 134\n",
      "training loss: 0.07795687\n",
      "validation loss: 0.17943020\n",
      "=========================================================\n",
      "Epoch 135\n",
      "training loss: 0.03936440\n",
      "validation loss: 0.18331233\n",
      "=========================================================\n",
      "Epoch 136\n",
      "training loss: 0.03507343\n",
      "validation loss: 0.16964899\n",
      "=========================================================\n",
      "Epoch 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.06925685\n",
      "validation loss: 0.16324605\n",
      "=========================================================\n",
      "Epoch 138\n",
      "training loss: 0.03389340\n",
      "validation loss: 0.17243634\n",
      "=========================================================\n",
      "Epoch 139\n",
      "training loss: 0.03822590\n",
      "validation loss: 0.20262899\n",
      "=========================================================\n",
      "Epoch 140\n",
      "training loss: 0.01355682\n",
      "validation loss: 0.19425535\n",
      "=========================================================\n",
      "Epoch 141\n",
      "training loss: 0.03909658\n",
      "validation loss: 0.22054680\n",
      "=========================================================\n",
      "Epoch 142\n",
      "training loss: 0.03846850\n",
      "validation loss: 0.18180686\n",
      "=========================================================\n",
      "Epoch 143\n",
      "training loss: 0.05446646\n",
      "validation loss: 0.16133648\n",
      "=========================================================\n",
      "Epoch 144\n",
      "training loss: 0.02776411\n",
      "validation loss: 0.15480620\n",
      "=========================================================\n",
      "Epoch 145\n",
      "training loss: 0.02282163\n",
      "validation loss: 0.16281769\n",
      "=========================================================\n",
      "Epoch 146\n",
      "training loss: 0.02804930\n",
      "validation loss: 0.17639989\n",
      "=========================================================\n",
      "Epoch 147\n",
      "training loss: 0.03241924\n",
      "validation loss: 0.17883392\n",
      "=========================================================\n",
      "Epoch 148\n",
      "training loss: 0.02175883\n",
      "validation loss: 0.16568613\n",
      "=========================================================\n",
      "Epoch 149\n",
      "training loss: 0.02018783\n",
      "validation loss: 0.16319877\n",
      "=========================================================\n",
      "Epoch 150\n",
      "training loss: 0.02693884\n",
      "validation loss: 0.15888397\n",
      "=========================================================\n",
      "Epoch 151\n",
      "training loss: 0.09281621\n",
      "validation loss: 0.13713618\n",
      "=========================================================\n",
      "Epoch 152\n",
      "training loss: 0.01288124\n",
      "validation loss: 0.13575153\n",
      "=========================================================\n",
      "Epoch 153\n",
      "training loss: 0.06875430\n",
      "validation loss: 0.12655982\n",
      "=========================================================\n",
      "Epoch 154\n",
      "training loss: 0.01643395\n",
      "validation loss: 0.12851664\n",
      "=========================================================\n",
      "Epoch 155\n",
      "training loss: 0.02614926\n",
      "validation loss: 0.13048537\n",
      "=========================================================\n",
      "Epoch 156\n",
      "training loss: 0.07515632\n",
      "validation loss: 0.13369581\n",
      "=========================================================\n",
      "Epoch 157\n",
      "training loss: 0.02058198\n",
      "validation loss: 0.13041317\n",
      "=========================================================\n",
      "Epoch 158\n",
      "training loss: 0.03087298\n",
      "validation loss: 0.12724271\n",
      "=========================================================\n",
      "Epoch 159\n",
      "training loss: 0.04983441\n",
      "validation loss: 0.14038025\n",
      "=========================================================\n",
      "Epoch 160\n",
      "training loss: 0.04405689\n",
      "validation loss: 0.14989322\n",
      "=========================================================\n",
      "Epoch 161\n",
      "training loss: 0.04495102\n",
      "validation loss: 0.18396457\n",
      "=========================================================\n",
      "Epoch 162\n",
      "training loss: 0.04263997\n",
      "validation loss: 0.16320352\n",
      "=========================================================\n",
      "Epoch 163\n",
      "training loss: 0.02775058\n",
      "validation loss: 0.15952055\n",
      "=========================================================\n",
      "Epoch 164\n",
      "training loss: 0.04534089\n",
      "validation loss: 0.15446146\n",
      "=========================================================\n",
      "Epoch 165\n",
      "training loss: 0.13105005\n",
      "validation loss: 0.12803350\n",
      "=========================================================\n",
      "Epoch 166\n",
      "training loss: 0.05919360\n",
      "validation loss: 0.15647933\n",
      "=========================================================\n",
      "Epoch 167\n",
      "training loss: 0.04654060\n",
      "validation loss: 0.14974496\n",
      "=========================================================\n",
      "Epoch 168\n",
      "training loss: 0.02873924\n",
      "validation loss: 0.14895418\n",
      "=========================================================\n",
      "Epoch 169\n",
      "training loss: 0.07240029\n",
      "validation loss: 0.14777087\n",
      "=========================================================\n",
      "Epoch 170\n",
      "training loss: 0.03839314\n",
      "validation loss: 0.11914347\n",
      "=========================================================\n",
      "Epoch 171\n",
      "training loss: 0.02277336\n",
      "validation loss: 0.12623078\n",
      "=========================================================\n",
      "Epoch 172\n",
      "training loss: 0.04607272\n",
      "validation loss: 0.14698130\n",
      "=========================================================\n",
      "Epoch 173\n",
      "training loss: 0.01713963\n",
      "validation loss: 0.15246962\n",
      "=========================================================\n",
      "Epoch 174\n",
      "training loss: 0.01063504\n",
      "validation loss: 0.15436110\n",
      "=========================================================\n",
      "Epoch 175\n",
      "training loss: 0.04614811\n",
      "validation loss: 0.14569476\n",
      "=========================================================\n",
      "Epoch 176\n",
      "training loss: 0.01637912\n",
      "validation loss: 0.14743160\n",
      "=========================================================\n",
      "Epoch 177\n",
      "training loss: 0.01469682\n",
      "validation loss: 0.15689214\n",
      "=========================================================\n",
      "Epoch 178\n",
      "training loss: 0.06953996\n",
      "validation loss: 0.16017887\n",
      "=========================================================\n",
      "Epoch 179\n",
      "training loss: 0.04569018\n",
      "validation loss: 0.15137821\n",
      "=========================================================\n",
      "Epoch 180\n",
      "training loss: 0.04770808\n",
      "validation loss: 0.17717932\n",
      "=========================================================\n",
      "Epoch 181\n",
      "training loss: 0.02389286\n",
      "validation loss: 0.17068273\n",
      "=========================================================\n",
      "Epoch 182\n",
      "training loss: 0.20089446\n",
      "validation loss: 0.16593146\n",
      "=========================================================\n",
      "Epoch 183\n",
      "training loss: 0.11871064\n",
      "validation loss: 0.11917894\n",
      "=========================================================\n",
      "Epoch 184\n",
      "training loss: 0.08870056\n",
      "validation loss: 0.14617576\n",
      "=========================================================\n",
      "Epoch 185\n",
      "training loss: 0.17217338\n",
      "validation loss: 0.17534316\n",
      "=========================================================\n",
      "Epoch 186\n",
      "training loss: 0.03526520\n",
      "validation loss: 0.19040614\n",
      "=========================================================\n",
      "Epoch 187\n",
      "training loss: 0.03298778\n",
      "validation loss: 0.19436911\n",
      "=========================================================\n",
      "Epoch 188\n",
      "training loss: 0.07100908\n",
      "validation loss: 0.19322848\n",
      "=========================================================\n",
      "Epoch 189\n",
      "training loss: 0.09872533\n",
      "validation loss: 0.16175015\n",
      "=========================================================\n",
      "Epoch 190\n",
      "training loss: 0.09880052\n",
      "validation loss: 0.15834141\n",
      "=========================================================\n",
      "Epoch 191\n",
      "training loss: 0.05056067\n",
      "validation loss: 0.18990582\n",
      "=========================================================\n",
      "Epoch 192\n",
      "training loss: 0.03297951\n",
      "validation loss: 0.18530394\n",
      "=========================================================\n",
      "Epoch 193\n",
      "training loss: 0.04732697\n",
      "validation loss: 0.17503580\n",
      "=========================================================\n",
      "Epoch 194\n",
      "training loss: 0.07843872\n",
      "validation loss: 0.16176791\n",
      "=========================================================\n",
      "Epoch 195\n",
      "training loss: 0.02204709\n",
      "validation loss: 0.16122076\n",
      "=========================================================\n",
      "Epoch 196\n",
      "training loss: 0.01593192\n",
      "validation loss: 0.16159192\n",
      "=========================================================\n",
      "Epoch 197\n",
      "training loss: 0.01579213\n",
      "validation loss: 0.16702488\n",
      "=========================================================\n",
      "Epoch 198\n",
      "training loss: 0.01762976\n",
      "validation loss: 0.17310350\n",
      "=========================================================\n",
      "Epoch 199\n",
      "training loss: 0.01480590\n",
      "validation loss: 0.18034297\n",
      "=========================================================\n",
      "Epoch 200\n",
      "training loss: 0.03879755\n",
      "validation loss: 0.17296261\n",
      "=========================================================\n",
      "Epoch 201\n",
      "training loss: 0.03635814\n",
      "validation loss: 0.14938754\n",
      "=========================================================\n",
      "Epoch 202\n",
      "training loss: 0.02610700\n",
      "validation loss: 0.15691444\n",
      "=========================================================\n",
      "Epoch 203\n",
      "training loss: 0.02144823\n",
      "validation loss: 0.17606705\n",
      "=========================================================\n",
      "Epoch 204\n",
      "training loss: 0.04049294\n",
      "validation loss: 0.16947697\n",
      "=========================================================\n",
      "Epoch 205\n",
      "training loss: 0.05079654\n",
      "validation loss: 0.18217129\n",
      "=========================================================\n",
      "Epoch 206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.04775035\n",
      "validation loss: 0.21201812\n",
      "=========================================================\n",
      "Epoch 207\n",
      "training loss: 0.02923838\n",
      "validation loss: 0.20307450\n",
      "=========================================================\n",
      "Epoch 208\n",
      "training loss: 0.02574859\n",
      "validation loss: 0.18973263\n",
      "=========================================================\n",
      "Epoch 209\n",
      "training loss: 0.02951869\n",
      "validation loss: 0.17872758\n",
      "=========================================================\n",
      "Epoch 210\n",
      "training loss: 0.00985409\n",
      "validation loss: 0.16993457\n",
      "=========================================================\n",
      "Epoch 211\n",
      "training loss: 0.05067019\n",
      "validation loss: 0.19217202\n",
      "=========================================================\n",
      "Epoch 212\n",
      "training loss: 0.02149034\n",
      "validation loss: 0.18797126\n",
      "=========================================================\n",
      "Epoch 213\n",
      "training loss: 0.01656326\n",
      "validation loss: 0.19245109\n",
      "=========================================================\n",
      "Epoch 214\n",
      "training loss: 0.01037452\n",
      "validation loss: 0.19184193\n",
      "=========================================================\n",
      "Epoch 215\n",
      "training loss: 0.02606281\n",
      "validation loss: 0.19256791\n",
      "=========================================================\n",
      "Epoch 216\n",
      "training loss: 0.01483120\n",
      "validation loss: 0.19256318\n",
      "=========================================================\n",
      "Epoch 217\n",
      "training loss: 0.03609931\n",
      "validation loss: 0.18950075\n",
      "=========================================================\n",
      "Epoch 218\n",
      "training loss: 0.03849073\n",
      "validation loss: 0.19200155\n",
      "=========================================================\n",
      "Epoch 219\n",
      "training loss: 0.03683040\n",
      "validation loss: 0.17669472\n",
      "=========================================================\n",
      "Epoch 220\n",
      "training loss: 0.01823567\n",
      "validation loss: 0.16727784\n",
      "=========================================================\n",
      "Epoch 221\n",
      "training loss: 0.03544324\n",
      "validation loss: 0.18272215\n",
      "=========================================================\n",
      "Epoch 222\n",
      "training loss: 0.01515304\n",
      "validation loss: 0.18910055\n",
      "=========================================================\n",
      "Epoch 223\n",
      "training loss: 0.04545254\n",
      "validation loss: 0.16902137\n",
      "=========================================================\n",
      "Epoch 224\n",
      "training loss: 0.02996388\n",
      "validation loss: 0.18421386\n",
      "=========================================================\n",
      "Epoch 225\n",
      "training loss: 0.02730290\n",
      "validation loss: 0.19514905\n",
      "=========================================================\n",
      "Epoch 226\n",
      "training loss: 0.01733374\n",
      "validation loss: 0.19278872\n",
      "=========================================================\n",
      "Epoch 227\n",
      "training loss: 0.01678568\n",
      "validation loss: 0.18243226\n",
      "=========================================================\n",
      "Epoch 228\n",
      "training loss: 0.01134844\n",
      "validation loss: 0.17727846\n",
      "=========================================================\n",
      "Epoch 229\n",
      "training loss: 0.08778848\n",
      "validation loss: 0.15963447\n",
      "=========================================================\n",
      "Epoch 230\n",
      "training loss: 0.02476835\n",
      "validation loss: 0.16529819\n",
      "=========================================================\n",
      "Epoch 231\n",
      "training loss: 0.06254731\n",
      "validation loss: 0.18820786\n",
      "=========================================================\n",
      "Epoch 232\n",
      "training loss: 0.01224956\n",
      "validation loss: 0.18403937\n",
      "=========================================================\n",
      "Epoch 233\n",
      "training loss: 0.01985458\n",
      "validation loss: 0.18260697\n",
      "=========================================================\n",
      "Epoch 234\n",
      "training loss: 0.02677336\n",
      "validation loss: 0.16538067\n",
      "=========================================================\n",
      "Epoch 235\n",
      "training loss: 0.02126778\n",
      "validation loss: 0.18274111\n",
      "=========================================================\n",
      "Epoch 236\n",
      "training loss: 0.01387639\n",
      "validation loss: 0.17781490\n",
      "=========================================================\n",
      "Epoch 237\n",
      "training loss: 0.04012590\n",
      "validation loss: 0.17551790\n",
      "=========================================================\n",
      "Epoch 238\n",
      "training loss: 0.00974452\n",
      "validation loss: 0.18503320\n",
      "=========================================================\n",
      "Epoch 239\n",
      "training loss: 0.01893865\n",
      "validation loss: 0.18564756\n",
      "=========================================================\n",
      "Epoch 240\n",
      "training loss: 0.00886363\n",
      "validation loss: 0.18981233\n",
      "=========================================================\n",
      "Epoch 241\n",
      "training loss: 0.00777233\n",
      "validation loss: 0.19247155\n",
      "=========================================================\n",
      "Epoch 242\n",
      "training loss: 0.02911293\n",
      "validation loss: 0.20494118\n",
      "=========================================================\n",
      "Epoch 243\n",
      "training loss: 0.02852664\n",
      "validation loss: 0.18059899\n",
      "=========================================================\n",
      "Epoch 244\n",
      "training loss: 0.01871093\n",
      "validation loss: 0.19658379\n",
      "=========================================================\n",
      "Epoch 245\n",
      "training loss: 0.02529971\n",
      "validation loss: 0.18964343\n",
      "=========================================================\n",
      "Epoch 246\n",
      "training loss: 0.00906607\n",
      "validation loss: 0.19664814\n",
      "=========================================================\n",
      "Epoch 247\n",
      "training loss: 0.05095129\n",
      "validation loss: 0.19393817\n",
      "=========================================================\n",
      "Epoch 248\n",
      "training loss: 0.02669687\n",
      "validation loss: 0.20563579\n",
      "=========================================================\n",
      "Epoch 249\n",
      "training loss: 0.01341012\n",
      "validation loss: 0.22473553\n",
      "=========================================================\n",
      "Epoch 250\n",
      "training loss: 0.02631267\n",
      "validation loss: 0.20114395\n",
      "=========================================================\n",
      "Epoch 251\n",
      "training loss: 0.01133853\n",
      "validation loss: 0.19460198\n",
      "=========================================================\n",
      "Epoch 252\n",
      "training loss: 0.01068819\n",
      "validation loss: 0.19119942\n",
      "=========================================================\n",
      "Epoch 253\n",
      "training loss: 0.01937228\n",
      "validation loss: 0.19727211\n",
      "=========================================================\n",
      "Epoch 254\n",
      "training loss: 0.00853065\n",
      "validation loss: 0.19784167\n",
      "=========================================================\n",
      "Epoch 255\n",
      "training loss: 0.04078418\n",
      "validation loss: 0.20833741\n",
      "=========================================================\n",
      "Epoch 256\n",
      "training loss: 0.01911126\n",
      "validation loss: 0.21316099\n",
      "=========================================================\n",
      "Epoch 257\n",
      "training loss: 0.04388184\n",
      "validation loss: 0.16211623\n",
      "=========================================================\n",
      "Epoch 258\n",
      "training loss: 0.03066231\n",
      "validation loss: 0.17422752\n",
      "=========================================================\n",
      "Epoch 259\n",
      "training loss: 0.02565877\n",
      "validation loss: 0.17574166\n",
      "=========================================================\n",
      "Epoch 260\n",
      "training loss: 0.03211776\n",
      "validation loss: 0.16477546\n",
      "=========================================================\n",
      "Epoch 261\n",
      "training loss: 0.04329918\n",
      "validation loss: 0.16430691\n",
      "=========================================================\n",
      "Epoch 262\n",
      "training loss: 0.02682962\n",
      "validation loss: 0.17003122\n",
      "=========================================================\n",
      "Epoch 263\n",
      "training loss: 0.08755204\n",
      "validation loss: 0.19103771\n",
      "=========================================================\n",
      "Epoch 264\n",
      "training loss: 0.10387227\n",
      "validation loss: 0.25976163\n",
      "=========================================================\n",
      "Epoch 265\n",
      "training loss: 0.01903264\n",
      "validation loss: 0.22953421\n",
      "=========================================================\n",
      "Epoch 266\n",
      "training loss: 0.01645280\n",
      "validation loss: 0.23585473\n",
      "=========================================================\n",
      "Epoch 267\n",
      "training loss: 0.02089704\n",
      "validation loss: 0.20226865\n",
      "=========================================================\n",
      "Epoch 268\n",
      "training loss: 0.01327738\n",
      "validation loss: 0.20964952\n",
      "=========================================================\n",
      "Epoch 269\n",
      "training loss: 0.10960495\n",
      "validation loss: 0.13926443\n",
      "=========================================================\n",
      "Epoch 270\n",
      "training loss: 0.02034906\n",
      "validation loss: 0.16263314\n",
      "=========================================================\n",
      "Epoch 271\n",
      "training loss: 0.02779786\n",
      "validation loss: 0.17832828\n",
      "=========================================================\n",
      "Epoch 272\n",
      "training loss: 0.01126959\n",
      "validation loss: 0.19469629\n",
      "=========================================================\n",
      "Epoch 273\n",
      "training loss: 0.05341664\n",
      "validation loss: 0.20309909\n",
      "=========================================================\n",
      "Epoch 274\n",
      "training loss: 0.01020821\n",
      "validation loss: 0.20293416\n",
      "=========================================================\n",
      "Epoch 275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss: 0.02418076\n",
      "validation loss: 0.21175413\n",
      "=========================================================\n",
      "Epoch 276\n",
      "training loss: 0.00966600\n",
      "validation loss: 0.20906350\n",
      "=========================================================\n",
      "Epoch 277\n",
      "training loss: 0.05668977\n",
      "validation loss: 0.23412009\n",
      "=========================================================\n",
      "Epoch 278\n",
      "training loss: 0.03784829\n",
      "validation loss: 0.21893384\n",
      "=========================================================\n",
      "Epoch 279\n",
      "training loss: 0.04616249\n",
      "validation loss: 0.22372964\n",
      "=========================================================\n",
      "Epoch 280\n",
      "training loss: 0.00757286\n",
      "validation loss: 0.22520638\n",
      "=========================================================\n",
      "Epoch 281\n",
      "training loss: 0.00653724\n",
      "validation loss: 0.22326362\n",
      "=========================================================\n",
      "Epoch 282\n",
      "training loss: 0.01831320\n",
      "validation loss: 0.22563206\n",
      "=========================================================\n",
      "Epoch 283\n",
      "training loss: 0.01484847\n",
      "validation loss: 0.22837768\n",
      "=========================================================\n",
      "Epoch 284\n",
      "training loss: 0.00919725\n",
      "validation loss: 0.22410908\n",
      "=========================================================\n",
      "Epoch 285\n",
      "training loss: 0.00821827\n",
      "validation loss: 0.22748414\n",
      "=========================================================\n",
      "Epoch 286\n",
      "training loss: 0.00682108\n",
      "validation loss: 0.22592261\n",
      "=========================================================\n",
      "Epoch 287\n",
      "training loss: 0.05283656\n",
      "validation loss: 0.26036984\n",
      "=========================================================\n",
      "Epoch 288\n",
      "training loss: 0.01761110\n",
      "validation loss: 0.24031730\n",
      "=========================================================\n",
      "Epoch 289\n",
      "training loss: 0.00965284\n",
      "validation loss: 0.22858129\n",
      "=========================================================\n",
      "Epoch 290\n",
      "training loss: 0.01616327\n",
      "validation loss: 0.20606609\n",
      "=========================================================\n",
      "Epoch 291\n",
      "training loss: 0.03167510\n",
      "validation loss: 0.21624888\n",
      "=========================================================\n",
      "Epoch 292\n",
      "training loss: 0.01368548\n",
      "validation loss: 0.22788639\n",
      "=========================================================\n",
      "Epoch 293\n",
      "training loss: 0.02272247\n",
      "validation loss: 0.20830621\n",
      "=========================================================\n",
      "Epoch 294\n",
      "training loss: 0.01452062\n",
      "validation loss: 0.21191040\n",
      "=========================================================\n",
      "Epoch 295\n",
      "training loss: 0.00404613\n",
      "validation loss: 0.21155629\n",
      "=========================================================\n",
      "Epoch 296\n",
      "training loss: 0.02375759\n",
      "validation loss: 0.22050433\n",
      "=========================================================\n",
      "Epoch 297\n",
      "training loss: 0.02864949\n",
      "validation loss: 0.21107073\n",
      "=========================================================\n",
      "Epoch 298\n",
      "training loss: 0.01290142\n",
      "validation loss: 0.21740578\n",
      "=========================================================\n",
      "Epoch 299\n",
      "training loss: 0.02051228\n",
      "validation loss: 0.24428986\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    " \n",
    "train_mean_losses = []\n",
    "valid_mean_losses = []\n",
    "\n",
    "valid_best_loss = np.inf\n",
    "\n",
    "for i in range(epochs):  \n",
    "    #===============================================================\n",
    "    # training \n",
    "    train_losses = []\n",
    "    \n",
    "    print(\"=========================================================\")\n",
    "    print(\"Epoch {}\".format(i))\n",
    "    \n",
    "    for iteration, batch_data in enumerate(train_loader):\n",
    "        X_batch, y_batch = batch_data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = net(X_batch)\n",
    "        loss = criterion(out, y_batch.squeeze())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss)\n",
    "    \n",
    "    train_mean_loss = torch.mean(torch.stack(train_losses))\n",
    "    print('training loss: {:10.8f}'.format(train_mean_loss))\n",
    "    \n",
    "    train_mean_losses.append(train_mean_loss)\n",
    "    \n",
    "    #===============================================================\n",
    "    # validation\n",
    "    valid_losses = []\n",
    "    with torch.set_grad_enabled(False):\n",
    "        for iteration, batch_data in enumerate(valid_loader):\n",
    "            X_batch, y_batch = batch_data\n",
    "\n",
    "            out = net(X_batch)\n",
    "            loss = criterion(out, y_batch.squeeze())\n",
    "            valid_losses.append(loss)\n",
    "            \n",
    "        valid_mean_loss = torch.mean(torch.stack(valid_losses))\n",
    "        print('validation loss: {:10.8f}'.format(valid_mean_loss))\n",
    "        \n",
    "        valid_mean_losses.append(valid_mean_loss)\n",
    "        \n",
    "        if valid_mean_loss.cpu().numpy()[()] < valid_best_loss:\n",
    "            valid_best_loss = valid_mean_loss\n",
    "            torch.save(net.state_dict(), \"best_model.pth\")\n",
    "            best_epoch = i\n",
    "    #===============================================================\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1,epochs+1), train_mean_losses)\n",
    "plt.plot(range(1,epochs+1), valid_mean_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Train and Validation Loss Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================\n",
      "\n",
      "Predicted Class:\n",
      "[1 2 2 1 2 1 0 1 0 2 2 1 0 1 2 0 2 1 2 2 0 0 1 2 0 2 1 0 1 0]\n",
      "\n",
      "Ground Truth:\n",
      "[1 2 2 2 2 2 0 1 0 2 2 1 0 1 2 0 2 1 2 2 0 0 1 2 0 2 1 0 1 0]\n",
      "\n",
      "=========================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2 11]]\n",
      "\n",
      "=========================================================\n",
      "\n",
      "Accuracy: 0.9333333333333333\n",
      "F1 Score:  0.9351851851851851\n",
      "\n",
      "=========================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       0.80      1.00      0.89         8\n",
      "           2       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.93      0.95      0.94        30\n",
      "weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = np.empty((0,3))\n",
    "with torch.no_grad():\n",
    "    for iteration, batch_data in enumerate(test_loader):\n",
    "        X_batch, y_batch = batch_data        \n",
    "        out = net(X_batch)\n",
    "        \n",
    "        test_predictions = np.append(test_predictions, out.numpy(), \n",
    "                                     axis=0)\n",
    "        \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_predictions = np.array(test_predictions)\n",
    "test_predictions = np.argmax(np.array(test_predictions), axis=1)\n",
    "\n",
    "print(\"=========================================================\\n\")\n",
    "print(\"Predicted Class:\")\n",
    "print(test_predictions)\n",
    "print(\"\\nGround Truth:\")\n",
    "print(test_y)\n",
    "\n",
    "print(\"\\n=========================================================\\n\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(test_y, test_predictions))\n",
    "\n",
    "print(\"\\n=========================================================\\n\")\n",
    "accuracy = accuracy_score(test_y, test_predictions)\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "f1 = f1_score(test_y, test_predictions, average='macro')\n",
    "print(\"F1 Score: \", f1)\n",
    "\n",
    "print(\"\\n=========================================================\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_y, test_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
